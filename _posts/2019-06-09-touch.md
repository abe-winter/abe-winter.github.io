---
layout: post
title: Touch interfaces aren't just bad on phones
author: Abe Winter
date: 2019-06-09
description: See me, feel me
categories: uxfail
---

My bathroom has one of those metal push-pads instead of a light switch and I have trouble operating it blind or while multitasking. 

This light switch is the same brand of trouble as my cell phone screen keyboard. I type 80+ wpm on most laptops and 100+ on my primary ([when the butterfly cooperates](https://ifixit.org/blog/14776/apples-butterfly-keyboard-continues-to-plague-macbook-owners/)) and can do that without sparing much attention. With the screen keyboard open, my attention is split between operating the keyboard and the 3 or 4 lines of cramped, clamped text I can see in a typical app text editor. = much less attention left over for composition and logic = crappy writing.

(I was 50 wpm on my blackberry bold, a device I replaced the keyboard on once, kept with a swelling battery, and only ditched when the charge port succumbed to wear).

There are some good reasons to have touch screens: they can switch between different interfaces, they're mechanically simple and easy to clean, they don't sacrifice screen space for a keyboard.

But they're totally unpleasant for any time-sensitive, expert or repeated task, especially when combined with the shoddy software and UX they usually put on these things. And they're particularly bad for entering text, which in the case of a cell phone is my primary use case.

1. toc
{:toc}

## Tactile feedback and finger placement

I'm particularly frustrated when registration is bad (i.e. your eye and the computer disagree about where you've touched).

The NYC metrocard machines have this problem because the touchscreen and the monitor are on different planes and I'm like three inches taller than the person who designed the box -- weird parallax effects. The NYC taxi seatback display has this problem because they're miscalibrated and the off button is tiny and in the corner.

I come from a line of primate ancestors who picked lice out of each other's hair; my hand-eye system was doing up-close manipulation for long millennia before we [learned how to throw](https://www.nature.com/articles/nature12267). If I can't operate a touch interface without careful attention, it's probably the screen's fault.

So what, you ask? Here's what: if computers are billing themselves as labor savers that improve individual welfare rather than annoying intrusions that complicate tasks we did fine on our own, they need to have usable interfaces that don't add stress to transactions.

I pine for Chicago 10 years ago when you could put in your card, put in a bill, and maybe press one button. If there was any kind of screen it was a tiny vacuum fluorescent numeral display that said how much money you put in. Those were the days.

## Unpredictable timing breaks my cerebellum

Actions that aren't instantaneous take more concentration because I can't execute a sequence of taps from muscle memory. Muscle memory happens in my cerebellum which is basically not even in my brain; I can use it without taking my higher brain functions off of whatever I was doing.

Actions that take variable amounts of time or frequently 'don't take' are even worse.

This may just be me but it feels like all the UXs I use have degraded timing as the version number goes up. My go-to examples are:

* the MTA metrocard machine, which has new 100+ millisecond lags and weird delays after rendering a screen before targets become tappable
* the android lock screen; I use a marshmallow (6) and a pie (9) device side by side. I can unlock the marshmallow most times on the first try quickly, whereas the pie gives me trouble and I have to slow down and look carefully. My guess is a combination of larger screen, smaller targets, less reliable gesture to open the passcode keyboard, and more tweening.

I've noticed recently that people who build software don't agree about which operations have to be fast.

Big companies run these studies every few years saying that page load time can ruin conversions; there was one from the mid 00s from google about slow SERP and there have been various others since then. And as a consequence everyone is aware of page load time as a thing. Game companies are the same way with frame rate. But many other operations are still slow.

If you're asking your users to wait for something, you had better give them a good reason. Computers felt pretty fast in the 90s! But today OSX's MS word clone takes more than 10 seconds to start, show me the wizards page, and create a blank document. My laptop is new and fast. This is a quality tradeoff that came down on the wrong side.

## Machine-learned UX isn't learnable by people

The flexibility of touchscreen interfaces is a pro and a con. Too much flexibility makes it hard for me as user to get consistent results.

I'm thinking here of the android swipe keyboard. This product shouldn't need complex stats to work but it's clearly using some, because like all ML products, it delivers impressive results once in a while crossed with inane or unsafe results most of the time. I screenshot when it's egregious. I have a bunch of cases of it trying to use the word 'orgy' and god forbid I ever try to type 'puffy jacket'.

While swipe-typing, I'm often outperformed by people who are moderately expert at apple's boring old screen keyboard which has better registration of fingers. My guess is that ios is better at this because they're not trying to distinguish btwn tap and swipe.

Also, like most statistically-driven products, it's getting worse over time -- slower and less reliable. I have to fight the results.

As my beloved Nexus 5 continues to degrade I can see it getting worse, but even my newish work pixel is taking longer to open the keyboard. Both struggle to detecting paths correctly when the device is taxed.

## Down with touch

Buttons everywhere.
