---
layout: post
title: Overton whiplash and bundled beliefs
description: Lift a stone and you will find me
author: Abe Winter
new: true
---

There are scary, exciting, heady moments where the frontier becomes the center.
Lenin said something about 'decades where nothing happen and weeks where decades happen'.
He was embalmed.
I've always wanted to film an eastern bloc 'weekend at bernie's' sequel with his remains.

This year has had more than its allotment of weeks.

One result of rapid change is that norms shift quickly.
I like the concept of the 'overton window' which claims that public policy exists on a spectrum from 'radical' to 'sensible' to 'popular'.
(Overton himself 'loved freedom' and therefore flew ultralights, which turned out to not be sensible -- he died in a crash).

In weeks where decades happen, the radical can become acceptable very quickly.
But radical ideas don't always stick, especially when they come with baggage.

* toc
{:toc}

## Some rocks you don't turn over

So an event happens, and suddenly the public is ready to listen to new perspectives,
but the only leaders in the 'new center' are (generously) contrarians or (less generously) half-baked.
One way to think of this is moving the spotlight.
Another is that you've flipped over a rock and there are crawly things that are no fun in the sun.

There's great value in occupying the 'new center' when the shift happens.
People like nouriel roubini and nassim taleb made their reputations on this in the 08 financial crisis.
George W bush has adjusted his reputation because he built up the CDC after SARS.

When someone camps in the fringe by making predictions, and turns out to be in the new center, you can accuse them of being 'stopped clocks' who were only right by luck.
This is an important question because being right once makes us want to listen to them about other things.
(Should I also take taleb's advice on picking a surgeon, for example; should I even listen to him on future financial crises).

When overton shifts happen in political or social norms,
leaders with fringe beliefs are briefly in the sunlight and we learn that they weren't just right about one thing:
they also have a host of other opinions that they'll talk your ear off about.

## Overton whiplash

By 'overton whiplash' I mean that shifts happen too quickly to weigh the change.
All we know is that we were wrong, and some thought leader was ahead of us, and we wonder whether to accept all of their opinions.
No political group has a monopoly on this kind of thing.

Here's an example from the conservative movement from the 70s, which I use because it's about the nuttiness of the fringe and because it's not recent enough for anyone to be offended ðŸ¤ž:

> One aspect of conservative complacency has been a growing toleration of the vicious lunatic fringe.
> The "no enemies to the right" policy has been symbolized in recent years by annual conservative "summits" in Washington --
> small, private dinners bringing together people like Bill Buckley, Irving Kristol, Norman Podhoretz, Charles Krauthammer, and the far-right activist Paul Weyrich.
> At one of these meetings, Weyrich circulated a proposal (which I have held and read) that the federal government secretly lace illegal drugs with substances like rat poison and release them into the black market.[^lind]

[^lind]: Michael Lind, [Why Intellectual Conservatism Died](http://www.dissentmagazine.org/pdfs/lind.pdf), Dissent magazine, via [this tweet](https://twitter.com/HeerJeet/status/1275867895059214338)

There are two elements to this 'whiplash':
* first that whiplash from the core issue changing makes a host of 'fellow traveler' issues seem briefly palatable,
* and second that the *non*-palatibility of the related beliefs drags the center backwards and hurts progress on the core issue.

You might object: people think critically and decide for themselves what to believe.
I'm currently reading [Thinking in Bets](https://www.annieduke.com/books/) and there's some footnotes in there which say we definitely don't always think critically, especially under time pressure.
The [Milgram experiment](https://en.wikipedia.org/wiki/Milgram_experiment) about following orders to shock people is sort of about this:
there are situations that rob us of our resources for disobedience, i.e. of thinking independently.

I saw a [twitter thread about medical advice in qanon forums](https://twitter.com/oneunderscore__/status/1276242069695143937) which made a similar claim:

> The woman in the QAnon group asking for help with her tinnitus received these suggestions:
> Itâ€™s your wifi. Go barefoot.
> Mind control labs are just shifting their frequency.
> "Your DNA is getting upgraded."
> Itâ€™s a common symptom of your mind awakening. Read my ebook.

The thread doesn't say what the outcome was (maybe the person quit the FB group).
But if the question is 'are people thinking critically', the answer should at least be 'not always'.

My problem with the philosophical literature of free will is that
the calvinists get busy linking omnipotence to determinism
and the physicists are probing for nondeterminism in the quantum ether,
but somewhere in america somebody's reflashing their linksys firmware to cure gout.

## Bundled beliefs

Various institutions bundle beliefs, from an intro course to an academic subject ('don't question everything in the textbook') to a cult ('question nothing or you're out / dead').

I think bundled beliefs are inherently problematic.
In the particular case of a fringe leader getting a broader platform, the tendency to consume bundled beliefs creates a brief (ðŸ¤ž) moment of widespread cultishness.

'If you really believe A you must also believe B' is a form of identity politics.
It's useful in that homogenous groups of voters tend to get what they want,
but it's strategically dangerous if the support for A is much higher than B;
you alienate people who should be on your side.

The worse consequence of bundling beliefs is that arguments against anything in the bundle is treated as an attack.

Yann LeCun, FB's AI superstar, wrote a post this week about 'argumentative norms' which I can no longer find because it's on facebook.
He got into a public fight for expressing an opinion about the source of bias in facial recognition or generative tools.
I don't know if he's right, but he didn't seem malicious and he's certainly a relevant voice about AI
(even, especially, if you think FB is evil).

Attacking arguments because they damage solidarity is at best short-sighted.
I had a job once with a relatively high amount of infighting,
and the only thing I learned there is that possessing good arguments leads to good outcomes.
(We didn't).

Movements or institutions that view dissent as an internal attack will never possess good arguments and will always suffer for it.

## Notes
{:.no_toc}

{% include flatpixel.html tag="whipton" %}
